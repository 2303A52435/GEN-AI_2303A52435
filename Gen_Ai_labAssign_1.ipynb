{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/bcTXywvp70UjxS6OIFxm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52435/GEN-AI_2303A52435/blob/main/Gen_Ai_labAssign_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=[10,20,30,40,50]\n",
        "yp=[10.2,20.5,30.3,40.8,50.6]"
      ],
      "metadata": {
        "id": "434sop0qcX95"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i in range(len(y)):\n",
        "    sum+=(y[i]-yp[i])**2\n",
        "mean_square_error=sum/len(y)\n",
        "print('the mean square error of the above data is: ',mean_square_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS65PyfMclrb",
        "outputId": "08da4ea0-8c3f-4883-c7e7-3a91481ecd21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean square error of the above data is:  0.27599999999999947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i in range(len(y)):\n",
        "    sum+=abs(y[i]-yp[i])\n",
        "mean_abs_error=sum/len(y)\n",
        "print('the mean abs error of the above data is: ',mean_abs_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lI0QYqUeOXM",
        "outputId": "f80c51b9-7269-4487-ccc4-1d1f42491cd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean abs error of the above data is:  0.4799999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('the root mean error of the above data is: ',(mean_square_error**0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ir5AUu6eWpt",
        "outputId": "92ed196b-6078-4a4b-9719-690c47738c7e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the root mean error of the above data is:  0.5253570214625474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "5pm8N8xGedNs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y, yp)\n",
        "print('The Mean Squared Error is:', mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRt3tTQeeg7T",
        "outputId": "5cca53e7-c88c-4cdb-9cf0-30a8339f66ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is: 0.27599999999999947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum=0\n",
        "for i in range(len(y)):\n",
        "    sum+=abs(y[i]-yp[i])\n",
        "mean_abs_error=sum/len(y)\n",
        "print('the mean abs error of the above data is: ',mean_abs_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrmcUusielrY",
        "outputId": "ec6ad4a4-742d-4507-a8b2-f8c66f484b49"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the mean abs error of the above data is:  0.4799999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('the root mean error of the above data is: ',(mean_square_error**0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHqKb7LoeoZT",
        "outputId": "47691a03-a00d-4862-b48f-7826e13e32c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the root mean error of the above data is:  0.5253570214625474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "metadata": {
        "id": "Day9w61TerOy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y, yp)\n",
        "print('The Mean Squared Error is:', mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci4nz40wewuH",
        "outputId": "685c14d2-921e-487c-8c9f-57c4c5ad9184"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Squared Error is: 0.27599999999999947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y, yp)\n",
        "print('The Mean Absolute Error is:', mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Us0xUkVe1Ua",
        "outputId": "df0a9ce6-3139-41fa-edcc-131542e8eb1e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Mean Absolute Error is: 0.4799999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse = mse**0.5  # RMSE is the square root of MSE\n",
        "print('The Root Mean Squared Error is:', rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KlsOpTee6b-",
        "outputId": "959420fa-773b-4e4d-97aa-ebeae49f75cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Root Mean Squared Error is: 0.5253570214625474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "yact=[0,0,0,0,0,1,1,1,1,1,1,2,2,2,2,2]\n",
        "ypred=[0,0,1,1,2,2,0,1,1,1,2,0,2,1,1,2]"
      ],
      "metadata": {
        "id": "ASbDxRX2fJ1A"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for i in range(len(yact)):\n",
        "    l.append([yact[i],ypred[i]])\n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tY-B9rGfJ_G",
        "outputId": "ab9a61b2-4920-481b-d283-5ecf9083d586"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0], [0, 0], [0, 1], [0, 1], [0, 2], [1, 2], [1, 0], [1, 1], [1, 1], [1, 1], [1, 2], [2, 0], [2, 2], [2, 1], [2, 1], [2, 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yact_set=list(sorted(set(yact)))\n",
        "yact_set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwVg7eU2fKIu",
        "outputId": "e26d9278-6e93-4d7e-c2ad-51efaeef99e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm=[]\n",
        "for i in yact_set:\n",
        "  temp=[]\n",
        "  for j in yact_set:\n",
        "    temp.append(l.count([i,j]))\n",
        "  cm.append(temp)"
      ],
      "metadata": {
        "id": "1h8v9hMmfZ1_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"confusionmatrix of above data is:\\n\",np.array(cm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdvcgkQjfaAk",
        "outputId": "4fbc7416-f0b1-4905-c720-e8bb5bbdd89b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusionmatrix of above data is:\n",
            " [[2 2 1]\n",
            " [1 3 2]\n",
            " [1 2 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_precision_recall_f1(cm):\n",
        "    total = builtins.sum(builtins.sum(row) for row in cm)\n",
        "    num_classes = len(cm)\n",
        "    precision = [0] * num_classes\n",
        "    recall = [0] * num_classes\n",
        "    f1_score = [0] * num_classes\n",
        "    tp_mat = []\n",
        "    fp_mat = []\n",
        "    fn_mat = []\n",
        "    tn_mat = []\n",
        "\n",
        "\n",
        "    for i in range(num_classes):  # Iterate over each class (rows)\n",
        "        # Calculate precision for class i\n",
        "        tp = cm[i][i]  # True Positives for class i\n",
        "        fp = 0\n",
        "        for j in range(num_classes):\n",
        "            if j != i:\n",
        "                fp += cm[j][i]  # False Positives for class i\n",
        "        if tp + fp != 0:  # Avoid division by zero\n",
        "            precision[i] = tp / (tp + fp)\n",
        "\n",
        "        # Calculate recall for class i\n",
        "        tp = cm[i][i]  # True Positives for class i\n",
        "        fn = 0\n",
        "        for j in range(num_classes):\n",
        "            if j != i:\n",
        "                fn += cm[i][j]  # False Negatives for class i\n",
        "        if tp + fn != 0:  # Avoid division by zero\n",
        "            recall[i] = tp / (tp + fn)\n",
        "                    # Calculate F1-score for class i\n",
        "        if precision[i] + recall[i] != 0:  # Avoid division by zero\n",
        "            f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])\n",
        "\n",
        "        tp_mat.append(tp)\n",
        "        fp_mat.append(fp)\n",
        "        fn_mat.append(fn)\n",
        "        tn_mat.append(total - tp - fp - fn)  # Use the total calculated outside the loop\n",
        "\n",
        "    # Return total along with other metrics\n",
        "    return precision, recall, f1_score, tp_mat, fp_mat, fn_mat, tn_mat, total\n",
        "\n",
        "import builtins # Import builtins module\n",
        "# Assuming 'cm' is defined as in your previous code\n",
        "precision_values, recall_values, f1_values, tp_mat, fp_mat, fn_mat, tn_mat, total = calculate_precision_recall_f1(cm)\n",
        "\n",
        "# Print results for each class\n",
        "for i in range(len(precision_values)):\n",
        "    print(f\"Class {i} - Precision: {precision_values[i]}, Recall: {recall_values[i]}, F1-Score: {f1_values[i]}\")\n",
        "\n",
        "# Print overall metrics\n",
        "print(f\"\\nOverall Accuracy: {np.sum(tp_mat)/total}\") # Using the calculated 'total' here\n",
        "print(f\"Overall Precision: {np.sum(tp_mat) / (np.sum(tp_mat) + np.sum(fp_mat))}\")\n",
        "print(f\"Overall Recall: {np.sum(tp_mat) / (np.sum(tp_mat) + np.sum(fn_mat)):.4f}\")\n",
        "print(f\"Overall F1-Score: {np.mean(f1_values)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQJV6PBKgOMX",
        "outputId": "bc3ea803-3bae-4c00-87bd-a080c4b47bac"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 - Precision: 0.5, Recall: 0.4, F1-Score: 0.4444444444444445\n",
            "Class 1 - Precision: 0.42857142857142855, Recall: 0.5, F1-Score: 0.4615384615384615\n",
            "Class 2 - Precision: 0.4, Recall: 0.4, F1-Score: 0.4000000000000001\n",
            "\n",
            "Overall Accuracy: 0.4375\n",
            "Overall Precision: 0.4375\n",
            "Overall Recall: 0.4375\n",
            "Overall F1-Score: 0.43532763532763535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(yact, ypred))\n",
        "\n",
        "# Classification Report (Precision, Recall, F1)\n",
        "print(\"Classification Report:\\n\", classification_report(yact, ypred))\n",
        "\n",
        "# Individual Metrics\n",
        "accuracy = accuracy_score(yact, ypred)\n",
        "precision = precision_score(yact, ypred, average='weighted')\n",
        "recall = recall_score(yact, ypred, average='weighted')\n",
        "f1 = f1_score(yact, ypred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvhCkvLfgRgT",
        "outputId": "9002b8c1-e87b-496f-b673-7ff3586aba49"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[2 2 1]\n",
            " [1 3 2]\n",
            " [1 2 2]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.40      0.44         5\n",
            "           1       0.43      0.50      0.46         6\n",
            "           2       0.40      0.40      0.40         5\n",
            "\n",
            "    accuracy                           0.44        16\n",
            "   macro avg       0.44      0.43      0.44        16\n",
            "weighted avg       0.44      0.44      0.44        16\n",
            "\n",
            "Accuracy: 0.4375\n",
            "Precision: 0.4419642857142857\n",
            "Recall: 0.4375\n",
            "F1-Score: 0.43696581196581197\n"
          ]
        }
      ]
    }
  ]
}